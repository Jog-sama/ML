<html lang="" dir="ltr">

<head>
  <meta charset="utf-8">
  <title>ML PRACS</title>
</head>

<body>

    <pre>
        import numpy as np
        import pandas as pd
        
        class SVM:
            def __init__(self, learning_rate=0.001, lambda_param=0.01, n_iters=1000):
                self.lr = learning_rate
                self.lambda_param = lambda_param
                self.n_iters = n_iters
                self.w = None
                self.b = None
        
            def fit(self, X, y):
                n_samples, n_features = X.shape
        
                # Initialize parameters
                self.w = np.zeros(n_features)
                self.b = 0
        
                # Gradient descent
                for _ in range(self.n_iters):
                    for idx, x_i in enumerate(X):
                        condition = y[idx] * (np.dot(x_i, self.w) - self.b) >= 1
                        if condition:
                            self.w -= self.lr * (2 * self.lambda_param * self.w)
                        else:
                            self.w -= self.lr * (2 * self.lambda_param * self.w - np.dot(x_i, y[idx]))
                            self.b -= self.lr * y[idx]
        
            def predict(self, X):
                return np.sign(np.dot(X, self.w) - self.b)
        
        # Example usage:
        data = pd.read_csv('data.csv')
        X_train = data.iloc[:, :-1].values
        y_train = data.iloc[:, -1].values.reshape(-1, 1)
        svm_model = SVM()
        svm_model.fit(X_train, y_train)
        X_test = np.array([[5.5, 3.5], [6.7, 3.0], [7.8, 3.8]])
        y_pred_test = svm_model.predict(X_test)
        print(y_pred_test)
        Heres how to use the code:
        
        First create a SVM object with the learning rate, regularization parameter and number of iterations as parameters.
        Then call the fit method of the object with the training data X_train and y_train.
        Finally call the predict method of the object with the test data X_test to get the predicted labels.
        To implement this code in PyCharm editor, you can create a new Python file and copy-paste the code into it. Then you can replace data.csv with your own dataset file name and run the code.
        
        
        import numpy as np
        class SVM:
        
            def __init__(self, C = 1.0):
                # C = error term
                self.C = C
                self.w = 0
                self.b = 0
        
            # Hinge Loss Function / Calculation
            def hingeloss(self, w, b, x, y):
                # Regularizer term
                reg = 0.5 * (w * w)
        
                for i in range(x.shape[0]):
                    # Optimization term
                    opt_term = y[i] * ((np.dot(w, x[i])) + b)
        
                    # calculating loss
                    loss = reg + self.C * max(0, 1-opt_term)
                return loss[0][0]
        
            def fit(self, X, Y, batch_size=100, learning_rate=0.001, epochs=1000):
                # The number of features in X
                number_of_features = X.shape[1]
        
                # The number of Samples in X
                number_of_samples = X.shape[0]
        
        
                # Creating ids from 0 to number_of_samples - 1
                ids = np.arange(number_of_samples)
        
                # Shuffling the samples randomly
                np.random.shuffle(ids)
        
                # creating an array of zeros
                w = np.zeros((1, number_of_features))
                b = 0
                losses = []
        
                # Gradient Descent logic
                for i in range(epochs):
                    # Calculating the Hinge Loss
                    l = self.hingeloss(w, b, X, Y)
        
                    # Appending all losses
                    losses.append(l)
        
                    # Starting from 0 to the number of samples with batch_size as interval
                    for batch_initial in range(0, number_of_samples, batch_size):
                        gradw = 0
                        gradb = 0
        
                        for j in range(batch_initial, batch_initial+ batch_size):
                            if j < number_of_samples:
                                x = ids[j]
                                ti = Y[x] * (np.dot(w, X[x].T) + b)
        
                                if ti > 1:
                                    gradw += 0
                                    gradb += 0
                                else:
                                    # Calculating the gradients
        
                                    #w.r.t w
                                    gradw += c * Y[x] * X[x]
                                    # w.r.t b
                                    gradb += c * Y[x]
        
                        # Updating weights and bias
                        w = w - learning_rate * w + learning_rate * gradw
                        b = b + learning_rate * gradb
        
                self.w = w
                self.b = b
        
                return self.w, self.b, losses
        
            def predict(self, X):
        
                prediction = np.dot(X, self.w[0]) + self.b # w.x + b
                return np.sign(prediction)

                from sklearn import datasets
                import matplotlib.pyplot as plt
                import numpy as np
                from sklearn.metrics import accuracy_score
                from sklearn.model_selection import train_test_split


                X, y = datasets.make_blobs(
                        n_samples = 100,
                        n_features = 2,
                        centers = 2,
                        cluster_std = 1,
                        random_state=40
                    )

                y = np.where(y == 0, -1, 1)

                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)

                svm = SVM()

                w, b, losses = svm.fit(X_train, y_train)


                Loading...
Skip to main content
exp 6 (SVM).ipynb
exp 6 (SVM).ipynb_Notebook unstarred
Changes will not be saved
[ ]
import numpy as np
class SVM:

    def __init__(self, C = 1.0):
        # C = error term
        self.C = C
        self.w = 0
        self.b = 0

    # Hinge Loss Function / Calculation
    def hingeloss(self, w, b, x, y):
        # Regularizer term
        reg = 0.5 * (w * w)

        for i in range(x.shape[0]):
            # Optimization term
            opt_term = y[i] * ((np.dot(w, x[i])) + b)

            # calculating loss
            loss = reg + self.C * max(0, 1-opt_term)
        return loss[0][0]

    def fit(self, X, Y, batch_size=100, learning_rate=0.001, epochs=1000):
        # The number of features in X
        number_of_features = X.shape[1]

        # The number of Samples in X
        number_of_samples = X.shape[0]


        # Creating ids from 0 to number_of_samples - 1
        ids = np.arange(number_of_samples)

        # Shuffling the samples randomly
        np.random.shuffle(ids)

        # creating an array of zeros
        w = np.zeros((1, number_of_features))
        b = 0
        losses = []

        # Gradient Descent logic
        for i in range(epochs):
            # Calculating the Hinge Loss
            l = self.hingeloss(w, b, X, Y)

            # Appending all losses
            losses.append(l)

            # Starting from 0 to the number of samples with batch_size as interval
            for batch_initial in range(0, number_of_samples, batch_size):
                gradw = 0
                gradb = 0

                for j in range(batch_initial, batch_initial+ batch_size):
                    if j < number_of_samples:
                        x = ids[j]
                        ti = Y[x] * (np.dot(w, X[x].T) + b)

                        if ti > 1:
                            gradw += 0
                            gradb += 0
                        else:
                            # Calculating the gradients

                            #w.r.t w
                            gradw += c * Y[x] * X[x]
                            # w.r.t b
                            gradb += c * Y[x]

                # Updating weights and bias
                w = w - learning_rate * w + learning_rate * gradw
                b = b + learning_rate * gradb

        self.w = w
        self.b = b

        return self.w, self.b, losses

    def predict(self, X):

        prediction = np.dot(X, self.w[0]) + self.b # w.x + b
        return np.sign(prediction)

            from sklearn import datasets
            import matplotlib.pyplot as plt
            import numpy as np
            from sklearn.metrics import accuracy_score
            from sklearn.model_selection import train_test_split


            X, y = datasets.make_blobs(
                    n_samples = 100,
                    n_features = 2,
                    centers = 2,
                    cluster_std = 1,
                    random_state=40
                )

            y = np.where(y == 0, -1, 1)
            [ ]
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)
            [ ]
            svm = SVM()

            w, b, losses = svm.fit(X_train, y_train)
            [ ]
            prediction = svm.predict(X_test)

            # Loss value
            lss = losses.pop()

            print("Loss:", lss)
            print("Prediction:", prediction)
            print("Accuracy:", accuracy_score(prediction, y_test))
            print("w, b:", [w, b])
            account_circle
            Loss: 0.0991126738798482
            Prediction: [-1.  1. -1. -1.  1.  1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1.
            1. -1.  1.  1. -1.  1.  1.  1. -1. -1. -1. -1.  1. -1. -1.  1.  1. -1.
            1. -1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.]
            Accuracy: 1.0
            w, b: [array([[0.44477983, 0.15109913]]), 0.05700000000000004]
            [ ]
            def visualize_dataset():
                plt.scatter(X[:, 0], X[:, 1], c=y)


            # Visualizing SVM
            def visualize_svm():

                def get_hyperplane_value(x, w, b, offset):
                    return (-w[0][0] * x + b + offset) / w[0][1]



    </pre>

</body>
</html>